{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","authorship_tag":"ABX9TyMuZD8dYhQRwIb/1/qfrt1r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KvClJkWeD-Rz","executionInfo":{"status":"ok","timestamp":1753757648779,"user_tz":240,"elapsed":21034,"user":{"displayName":"Aarush Kumar","userId":"16118659533235147067"}},"outputId":"93998a35-cd07-44d4-8f37-38d7b6ecdeef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, Bidirectional\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","dir = '/content/drive/My Drive/poems/PoemDataset.csv'\n","df = pd.read_csv(dir)\n","\n","df = df[['Poem', 'Genre']].dropna()\n","\n","def preprocess_text(row):\n","    return f\"{row['Genre']} <START> {row['Poem']} <END>\"\n","\n","df['processed'] = df.apply(preprocess_text, axis=1)\n","\n","texts = df['processed'].str.lower().tolist()\n","\n","tokenizer = Tokenizer(oov_token='<OOV>')\n","tokenizer.fit_on_texts(texts)\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","print(f\"Vocabulary size: {vocab_size}\")\n","\n","sequences = tokenizer.texts_to_sequences(texts)\n","\n","seq_length = 20\n","X = []\n","y = []\n","\n","for seq in sequences:\n","    for i in range(1, len(seq)):\n","        start_idx = max(0, i - seq_length)\n","        seq_in = seq[start_idx:i]\n","        seq_out = seq[i]\n","        seq_in = pad_sequences([seq_in], maxlen=seq_length, padding='pre')[0]\n","        X.append(seq_in)\n","        y.append(seq_out)\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","print(f\"Total sequences: {X.shape[0]}\")\n","\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n","\n","class_weights = compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(y_train),\n","    y=y_train\n",")\n","class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n","\n","y_train_cat = to_categorical(y_train, num_classes=vocab_size)\n","y_val_cat = to_categorical(y_val, num_classes=vocab_size)\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=seq_length))\n","model.add(Bidirectional(LSTM(256, return_sequences=True)))\n","model.add(Dropout(0.3))\n","model.add(Bidirectional(LSTM(256)))\n","model.add(Dropout(0.3))\n","model.add(Dense(vocab_size, activation='softmax'))\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n","\n","model.fit(\n","    X_train, y_train_cat,\n","    validation_data=(X_val, y_val_cat),\n","    epochs=20,\n","    batch_size=32,\n","    callbacks=[early_stop],\n","    class_weight=class_weight_dict,\n","    verbose=1\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"id":"P2wHnOGwEBb2","outputId":"396aa333-69d0-4c98-b1e9-28479be742ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 181939\n","Total sequences: 2444196\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"code","source":["from keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","def generate_poem(model, tokenizer, emotion, seq_length=20, max_words=50):\n","    seed_text = f\"{emotion.lower()} <start>\"\n","    result = seed_text.split()\n","\n","    for _ in range(max_words):\n","        encoded = tokenizer.texts_to_sequences([' '.join(result)])[0]\n","        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre')\n","\n","        preds = model.predict(encoded, verbose=0)[0]\n","        next_index = np.argmax(preds)\n","        next_word = tokenizer.index_word.get(next_index, '')\n","\n","        if next_word == '<end>' or next_word == '':\n","            break\n","\n","        result.append(next_word)\n","\n","    return ' '.join(result[2:])\n","\n","print(generate_poem(model, tokenizer, 'Joy'))\n"],"metadata":{"id":"Lh8Fhe6WE_hP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BsXJdr6WFCIm"},"execution_count":null,"outputs":[]}]}