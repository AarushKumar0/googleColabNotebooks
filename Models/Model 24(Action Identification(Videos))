{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPjHy08bKN0PEAMxZyzOGy1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1sgPrM1_bdL5","executionInfo":{"status":"ok","timestamp":1754971563823,"user_tz":240,"elapsed":14125,"user":{"displayName":"Aarush Kumar","userId":"16118659533235147067"}},"outputId":"31bf7b40-5c5f-42c3-d00e-266519951c5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","data_path = '/content/drive/My Drive/ucfvideos/UCF101'"]},{"cell_type":"code","source":["!pip install av\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"INXOI9x3dWf5","executionInfo":{"status":"ok","timestamp":1755138019425,"user_tz":240,"elapsed":9715,"user":{"displayName":"Aarush Kumar","userId":"16118659533235147067"}},"outputId":"593aca1e-88bc-4a6d-9ab5-9757aebc1fdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting av\n","  Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n","Downloading av-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: av\n","Successfully installed av-15.0.0\n"]}]},{"cell_type":"code","source":["\n","import os\n","import random\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","import av\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Set your dataset path here (make sure it points to folder with class subfolders)\n","DATA_PATH = '/content/drive/My Drive/ucfvideos/UCF101/UCF-101'\n","\n","# 1. Get all videos and classes\n","classes = sorted([d for d in os.listdir(DATA_PATH) if os.path.isdir(os.path.join(DATA_PATH, d))])\n","class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n","\n","all_videos = []\n","for cls in classes:\n","    cls_path = os.path.join(DATA_PATH, cls)\n","    for fname in os.listdir(cls_path):\n","        if fname.endswith('.avi'):\n","            all_videos.append((os.path.join(cls, fname), class_to_idx[cls]))\n","\n","print(f\"Found {len(all_videos)} videos from {len(classes)} classes\")\n","\n","# 2. Split into train/val/test 70/15/15\n","random.seed(42)\n","random.shuffle(all_videos)\n","num_total = len(all_videos)\n","num_train = int(0.7 * num_total)\n","num_val = int(0.15 * num_total)\n","\n","train_videos = all_videos[:num_train]\n","val_videos = all_videos[num_train:num_train + num_val]\n","test_videos = all_videos[num_train + num_val:]\n","\n","print(f\"Train: {len(train_videos)}, Val: {len(val_videos)}, Test: {len(test_videos)}\")\n","\n","# 3. Helper to convert frames to tensor\n","def video_to_tensor(frames):\n","    frames = np.stack(frames).astype(np.float32) / 255.0  # shape (T,H,W,C)\n","    frames = torch.from_numpy(frames).permute(3, 0, 1, 2)  # (C,T,H,W)\n","    return frames\n","\n","# 4. Dataset class\n","class UCF101Dataset(Dataset):\n","    def __init__(self, video_label_list, data_path, clip_len=16, transform=None):\n","        self.video_label_list = video_label_list\n","        self.data_path = data_path\n","        self.clip_len = clip_len\n","        self.transform = transform  # PIL-compatible transforms (no ToTensor!)\n","\n","    def __len__(self):\n","        return len(self.video_label_list)\n","\n","    def __getitem__(self, idx):\n","        video_rel_path, label = self.video_label_list[idx]\n","        video_path = os.path.join(self.data_path, video_rel_path)\n","\n","        container = av.open(video_path)\n","        frames = []\n","        for frame in container.decode(video=0):\n","            img = frame.to_image().resize((112,112))\n","            if self.transform:\n","                img = self.transform(img)\n","            frames.append(np.array(img))\n","        container.close()\n","\n","        total_frames = len(frames)\n","        if total_frames < self.clip_len:\n","            frames += [frames[-1]] * (self.clip_len - total_frames)\n","        else:\n","            indices = np.linspace(0, total_frames - 1, self.clip_len).astype(int)\n","            frames = [frames[i] for i in indices]\n","\n","        video_tensor = video_to_tensor(frames)  # shape (3, clip_len, 112, 112)\n","        return video_tensor, label\n","\n","# 5. Define transform (resize done in Dataset, so can be None or augmentation without ToTensor)\n","transform = None\n","\n","# 6. Create Datasets and DataLoaders\n","train_dataset = UCF101Dataset(train_videos, DATA_PATH, clip_len=16, transform=transform)\n","val_dataset = UCF101Dataset(val_videos, DATA_PATH, clip_len=16, transform=transform)\n","test_dataset = UCF101Dataset(test_videos, DATA_PATH, clip_len=16, transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n","test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)\n","\n","# 7. Define your custom 3D CNN model\n","class Simple3DCNN(nn.Module):\n","    def __init__(self, num_classes):\n","        super(Simple3DCNN, self).__init__()\n","        self.conv1 = nn.Conv3d(3, 16, kernel_size=(3,3,3), padding=1)\n","        self.pool1 = nn.MaxPool3d((1,2,2))  # downsample spatially, keep time\n","        self.conv2 = nn.Conv3d(16, 32, kernel_size=(3,3,3), padding=1)\n","        self.pool2 = nn.MaxPool3d((2,2,2))  # downsample time and space\n","        self.conv3 = nn.Conv3d(32, 64, kernel_size=(3,3,3), padding=1)\n","        self.pool3 = nn.AdaptiveAvgPool3d((1,1,1))  # global avg pool\n","        self.fc = nn.Linear(64, num_classes)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))    # (B,16,T,H,W)\n","        x = self.pool1(x)            # (B,16,T,H/2,W/2)\n","        x = F.relu(self.conv2(x))    # (B,32,T,H/2,W/2)\n","        x = self.pool2(x)            # (B,32,T/2,H/4,W/4)\n","        x = F.relu(self.conv3(x))    # (B,64,T/2,H/4,W/4)\n","        x = self.pool3(x)            # (B,64,1,1,1)\n","        x = x.view(x.size(0), -1)    # flatten to (B,64)\n","        x = self.fc(x)               # (B,num_classes)\n","        return x\n","\n","# 8. Setup device, model, loss, optimizer\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Simple3DCNN(num_classes=len(classes)).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# 9. Training loop\n","def train_one_epoch(model, loader, criterion, optimizer, device):\n","    model.train()\n","    total_loss = 0\n","    total_correct = 0\n","    total = 0\n","    for videos, labels in loader:\n","        videos = videos.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(videos)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item() * videos.size(0)\n","        _, preds = outputs.max(1)\n","        total_correct += preds.eq(labels).sum().item()\n","        total += videos.size(0)\n","    avg_loss = total_loss / total\n","    accuracy = total_correct / total\n","    print(f\"Train loss: {avg_loss:.4f}, accuracy: {accuracy:.4f}\")\n","\n","# 10. Evaluation loop\n","def evaluate(model, loader, device):\n","    model.eval()\n","    total_correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for videos, labels in loader:\n","            videos = videos.to(device)\n","            labels = labels.to(device)\n","            outputs = model(videos)\n","            _, preds = outputs.max(1)\n","            total_correct += preds.eq(labels).sum().item()\n","            total += videos.size(0)\n","    accuracy = total_correct / total\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","\n","# 11. Run training and validation for 5 epochs\n","for epoch in range(1, 6):\n","    print(f\"Epoch {epoch}\")\n","    train_one_epoch(model, train_loader, criterion, optimizer, device)\n","    print(\"Validation:\")\n","    evaluate(model, val_loader, device)\n","\n","print(\"Final test accuracy:\")\n","evaluate(model, test_loader, device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"GW8FOxPgcn2A","executionInfo":{"status":"error","timestamp":1755138037092,"user_tz":240,"elapsed":15183,"user":{"displayName":"Aarush Kumar","userId":"16118659533235147067"}},"outputId":"9daf2f15-8d8b-48f4-d086-ae2f8feaeea2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/My Drive/ucfvideos/UCF101/UCF-101'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2396384966.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 1. Get all videos and classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/ucfvideos/UCF101/UCF-101'"]}]}]}