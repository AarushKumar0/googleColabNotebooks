{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOF9T/D0euWMGmwbwiPOT/D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install opencv-python-headless albumentations pycocotools av moviepy\n","\n","import os\n","import cv2\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import av\n","\n","def parse_annotations(anno_path):\n","    boxes, labels = [], []\n","    with open(anno_path, 'r') as f:\n","        for line in f.readlines():\n","            x, y, w, h, score, category, truncation, occlusion = map(int, line.strip().split(','))\n","            boxes.append([x, y, x+w, y+h])\n","            labels.append(category)\n","    return np.array(boxes), np.array(labels)\n","\n","def load_video_frames(video_path, num_frames=16):\n","    container = av.open(video_path)\n","    frames = []\n","    total_frames = container.streams.video[0].frames\n","    step = max(total_frames // num_frames, 1)\n","    for i, frame in enumerate(container.decode(video=0)):\n","        if i % step == 0 and len(frames) < num_frames:\n","            img = frame.to_rgb().to_ndarray()\n","            img = cv2.resize(img, (224, 224))\n","            frames.append(img)\n","        if len(frames) == num_frames:\n","            break\n","    container.close()\n","    return np.array(frames)\n","\n","class VisDroneVideoDataset(Dataset):\n","    def __init__(self, video_dir, anno_dir, transform=None, num_frames=16):\n","        self.video_dir = video_dir\n","        self.anno_dir = anno_dir\n","        self.transform = transform\n","        self.num_frames = num_frames\n","        self.video_files = sorted([f for f in os.listdir(video_dir) if f.endswith('.mp4')])\n","\n","    def __len__(self):\n","        return len(self.video_files)\n","\n","    def __getitem__(self, idx):\n","        video_file = self.video_files[idx]\n","        video_path = os.path.join(self.video_dir, video_file)\n","        anno_file = os.path.join(self.anno_dir, video_file.replace('.mp4', '.txt'))\n","\n","        frames = load_video_frames(video_path, self.num_frames)\n","        boxes, labels = parse_annotations(anno_file)\n","\n","        if self.transform:\n","            augmented_frames = []\n","            for frame in frames:\n","                transformed = self.transform(image=frame)\n","                augmented_frames.append(transformed['image'])\n","            frames = torch.stack(augmented_frames)  # (T, C, H, W)\n","        else:\n","            frames = torch.from_numpy(frames).permute(0, 3, 1, 2).float() / 255.0\n","\n","        target = {\n","            \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n","            \"labels\": torch.tensor(labels, dtype=torch.long)\n","        }\n","        return frames, target\n","\n","# ===================== 5. DataLoader & Transform =====================\n","transform = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.RandomBrightnessContrast(p=0.2),\n","    A.Normalize(),\n","    ToTensorV2()\n","])\n","\n","VIDEO_DIR = '/content/drive/My Drive/VisDrone'\n","ANNO_DIR  = '/content/drive/My Drive/VisDrone/annotations'\n","\n","train_dataset = VisDroneVideoDataset(\n","    video_dir=os.path.join(VIDEO_DIR, 'VisDrone2019-DET-train/images'),\n","    anno_dir=os.path.join(ANNO_DIR, 'train'),\n","    transform=transform\n",")\n","train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2)\n","\n","val_dataset = VisDroneVideoDataset(\n","    video_dir=os.path.join(VIDEO_DIR, 'VisDrone2019-DET-val/images'),\n","    anno_dir=os.path.join(ANNO_DIR, 'val'),\n","    transform=transform\n",")\n","val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=2)\n","\n","# ===================== 6. Fully Custom 3D CNN =====================\n","class Custom3DCNN(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv3d(3, 32, kernel_size=(3,3,3), padding=1),\n","            nn.BatchNorm3d(32),\n","            nn.ReLU(),\n","            nn.MaxPool3d((1,2,2)),\n","\n","            nn.Conv3d(32, 64, kernel_size=(3,3,3), padding=1),\n","            nn.BatchNorm3d(64),\n","            nn.ReLU(),\n","            nn.MaxPool3d((2,2,2)),\n","\n","            nn.Conv3d(64, 128, kernel_size=(3,3,3), padding=1),\n","            nn.BatchNorm3d(128),\n","            nn.ReLU(),\n","            nn.MaxPool3d((2,2,2))\n","        )\n","\n","        self.detector = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(128*2*28*28, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, num_classes*4)  # predict bounding boxes\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(128*2*28*28, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, num_classes)  # predict class labels\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        boxes = self.detector(x)\n","        classes = self.classifier(x)\n","        return boxes, classes\n","\n","# ===================== 7. Training Setup =====================\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_classes = 10  # set this to your VisDrone classes\n","model = Custom3DCNN(num_classes=num_classes).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-4)\n","criterion_cls = nn.CrossEntropyLoss()\n","criterion_reg = nn.SmoothL1Loss()\n","\n","def train_epoch(model, loader, optimizer):\n","    model.train()\n","    total_loss = 0\n","    for frames, target in loader:\n","        frames = frames.permute(0, 2, 1, 3, 4).float().to(device)  # (B,C,T,H,W)\n","        boxes_true = target[\"boxes\"].to(device)\n","        labels_true = target[\"labels\"].to(device)\n","\n","        optimizer.zero_grad()\n","        boxes_pred, classes_pred = model(frames)\n","\n","        loss_cls = criterion_cls(classes_pred, labels_true)\n","        loss_reg = criterion_reg(boxes_pred, boxes_true.view(boxes_true.size(0), -1))\n","        loss = loss_cls + loss_reg\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","    return total_loss / len(loader)\n","\n","def predict_video(model, video_path):\n","    model.eval()\n","    frames = load_video_frames(video_path)\n","    frames = torch.stack([transform(image=frame)[\"image\"] for frame in frames])\n","    frames = frames.unsqueeze(0).permute(0,2,1,3,4).float().to(device)\n","    with torch.no_grad():\n","        boxes, classes = model(frames)\n","    return boxes.cpu().numpy(), classes.cpu().numpy()\n"],"metadata":{"id":"QNmDT0HfRKQ1"},"execution_count":null,"outputs":[]}]}