{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP14Ti0ltuuFo03hMlzJzqV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","\n","\n","csv_path = \"/content/drive/My Drive/DNA_DATASET/peak_based_dna_sequences.csv\"\n","img_folder = \"/content/drive/My Drive/DNA_DATASET/augmented/\"\n","\n","df = pd.read_csv(csv_path, sep=\",\")\n","df.columns = df.columns.str.strip()\n","print(df.columns.tolist())\n","\n","\n","VOCAB = ['<PAD>', '<SOS>', '<EOS>', 'A', 'T', 'C', 'G']\n","stoi = {ch:i for i,ch in enumerate(VOCAB)}\n","itos = {i:ch for i,ch in enumerate(VOCAB)}\n","\n","MAX_LEN = 200\n","\n","def encode_seq(seq, max_len=MAX_LEN):\n","    tokens = [stoi['<SOS>']] + [stoi[ch] for ch in seq if ch in stoi] + [stoi['<EOS>']]\n","    tokens = tokens[:max_len] + [stoi['<PAD>']]*(max_len - len(tokens))\n","    return np.array(tokens)\n","\n","def decode_seq(tokens):\n","    result = []\n","    for t in tokens:\n","        if t == stoi['<EOS>']:\n","            break\n","        if t in [stoi['<SOS>'], stoi['<PAD>']]:\n","            continue\n","        result.append(itos[t])\n","    return \"\".join(result)\n","\n","df['encoded_seq'] = df['Peak_Based_DNA_Sequence'].apply(lambda x: encode_seq(x))\n","\n","\n","from sklearn.model_selection import train_test_split\n","train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","\n","class DNADataset(Dataset):\n","    def __init__(self, df, img_folder, transform=None):\n","        self.df = df\n","        self.img_folder = img_folder\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        img_path = os.path.join(self.img_folder, row['Image_Name'])\n","        img = Image.open(img_path).convert(\"RGB\")\n","        if self.transform:\n","            img = self.transform(img)\n","        seq = torch.tensor(row['encoded_seq'], dtype=torch.long)\n","        return img, seq\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","])\n","\n","train_dataset = DNADataset(train_df, img_folder, transform)\n","val_dataset = DNADataset(val_df, img_folder, transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=16)\n","\n","\n","import torch.nn as nn\n","\n","class CustomCNN(nn.Module):\n","    def __init__(self, embed_size=256):\n","        super(CustomCNN, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(32, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(64, 128, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(128, 256, 3, padding=1),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool2d((1,1))\n","        )\n","        self.fc = nn.Linear(256, embed_size)\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n","\n","class DecoderRNN(nn.Module):\n","    def __init__(self, embed_size, hidden_size, vocab_size):\n","        super(DecoderRNN, self).__init__()\n","        self.embed = nn.Embedding(vocab_size, embed_size)\n","        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, vocab_size)\n","\n","    def forward(self, features, captions):\n","        embeddings = self.embed(captions[:, :-1])\n","        features = features.unsqueeze(1)\n","        inputs = torch.cat((features, embeddings), dim=1)\n","        hiddens, _ = self.lstm(inputs)\n","        outputs = self.fc(hiddens)\n","        outputs = outputs[:, 1:, :]  # slice to match captions[:,1:]\n","        return outputs\n","\n","\n","class Image2Seq(nn.Module):\n","    def __init__(self, embed_size, hidden_size, vocab_size):\n","        super(Image2Seq, self).__init__()\n","        self.encoder = CustomCNN(embed_size)\n","        self.decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n","\n","    def forward(self, images, captions):\n","        features = self.encoder(images)\n","        outputs = self.decoder(features, captions)\n","        return outputs\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","embed_size = 256\n","hidden_size = 512\n","vocab_size = len(VOCAB)\n","\n","model = Image2Seq(embed_size, hidden_size, vocab_size).to(device)\n","criterion = nn.CrossEntropyLoss(ignore_index=stoi['<PAD>'])\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","EPOCHS = 10\n","\n","\n","def calc_accuracy(preds, targets):\n","    # preds: (B, seq_len, vocab_size), targets: (B, seq_len)\n","    preds_tokens = preds.argmax(-1)\n","    mask = targets != stoi['<PAD>']\n","    correct = (preds_tokens == targets) * mask\n","    acc = correct.sum().item() / mask.sum().item()\n","    return acc\n","\n","for epoch in range(EPOCHS):\n","    model.train()\n","    total_loss = 0\n","    total_acc = 0\n","    for imgs, seqs in train_loader:\n","        imgs, seqs = imgs.to(device), seqs.to(device)\n","        outputs = model(imgs, seqs)\n","        target = seqs[:, 1:]\n","        loss = criterion(outputs.reshape(-1, vocab_size), target.reshape(-1))\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","        total_acc += calc_accuracy(outputs, target)\n","\n","    print(f\"Epoch {epoch+1}/{EPOCHS}, \"\n","          f\"Train Loss: {total_loss/len(train_loader):.4f}, \"\n","          f\"Train Acc: {total_acc/len(train_loader):.4f}\")\n","\n","    # Validation Accuracy\n","    model.eval()\n","    val_acc = 0\n","    with torch.no_grad():\n","        for imgs, seqs in val_loader:\n","            imgs, seqs = imgs.to(device), seqs.to(device)\n","            outputs = model(imgs, seqs)\n","            target = seqs[:,1:]\n","            val_acc += calc_accuracy(outputs, target)\n","    print(f\"Validation Acc: {val_acc/len(val_loader):.4f}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":697},"id":"CVUJ94HgwAK6","executionInfo":{"status":"error","timestamp":1756520236906,"user_tz":240,"elapsed":151225,"user":{"displayName":"Aarush Kumar","userId":"16118659533235147067"}},"outputId":"4e20c84e-5c34-4493-b93c-89a4b27dda6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","['Image_Name', 'Peak_Based_DNA_Sequence']\n","Epoch 1/10, Train Loss: 0.8528, Train Acc: 0.7329\n","Validation Acc: 0.8600\n","Epoch 2/10, Train Loss: 0.5501, Train Acc: 0.8449\n","Validation Acc: 0.8696\n","Epoch 3/10, Train Loss: 0.5369, Train Acc: 0.8482\n","Validation Acc: 0.8694\n","Epoch 4/10, Train Loss: 0.5202, Train Acc: 0.8490\n","Validation Acc: 0.8681\n","Epoch 5/10, Train Loss: 0.5149, Train Acc: 0.8476\n","Validation Acc: 0.8695\n","Epoch 6/10, Train Loss: 0.5075, Train Acc: 0.8501\n","Validation Acc: 0.8697\n","Epoch 7/10, Train Loss: 0.5062, Train Acc: 0.8489\n","Validation Acc: 0.8698\n","Epoch 8/10, Train Loss: 0.4991, Train Acc: 0.8502\n","Validation Acc: 0.8693\n","Epoch 9/10, Train Loss: 0.4955, Train Acc: 0.8504\n","Validation Acc: 0.8690\n","Epoch 10/10, Train Loss: 0.4976, Train Acc: 0.8490\n","Validation Acc: 0.8695\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"a Tensor with 7 elements cannot be converted to Scalar","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2329511797.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;31m# ===========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0msample_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Image_Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ground truth:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Peak_Based_DNA_Sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2329511797.py\u001b[0m in \u001b[0;36mpredict_sequence\u001b[0;34m(img_path, model, max_len)\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<EOS>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 7 elements cannot be converted to Scalar"]}]}]}