{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN+ZcPYtBdQnFIiUDeYBMmf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Bidirectional, Concatenate, TimeDistributed, AdditiveAttention\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","import pandas as pd\n","\n","csv_path = '/content/drive/My Drive/stories/train.csv'\n","\n","df = pd.read_csv(csv_path)\n","\n","stories = df['text'].dropna().tolist()\n","print(f\"Loaded {len(stories)} stories.\")\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","\n","\n","tokenizer = Tokenizer(oov_token=\"<unk>\")\n","tokenizer.fit_on_texts(stories)\n","vocab_size = len(tokenizer.word_index) + 1\n","print(\"Vocabulary size:\", vocab_size)\n","\n","sequences = tokenizer.texts_to_sequences(stories)\n","\n","seq_length = 10\n","X, y = [], []\n","\n","for seq in sequences:\n","    for i in range(1, len(seq)):\n","        start_idx = max(0, i - seq_length)\n","        seq_in = seq[start_idx:i]\n","        seq_out = seq[i]\n","        seq_in = pad_sequences([seq_in], maxlen=seq_length, padding='pre')[0]\n","        X.append(seq_in)\n","        y.append(seq_out)\n","\n","X = np.array(X)\n","y = np.array(y)\n","print(f\"Prepared {X.shape[0]} sequences.\")\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","model = Sequential([\n","    Embedding(input_dim=vocab_size, output_dim=50, input_length=seq_length),\n","    LSTM(128, return_sequences=True),\n","    LSTM(128),\n","    Dense(vocab_size, activation='softmax')\n","])\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()\n","model.fit(X, y, epochs=50, batch_size=16)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5YaXbCH2_po","outputId":"6618d868-2b68-4a77-9f63-38874a0267e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Loaded 2119489 stories.\n","Vocabulary size: 63087\n"]}]},{"cell_type":"code","source":["def generate_story(model, tokenizer, seed_text, next_words=50):\n","    result = seed_text.split()\n","    seq_length = model.input_shape[1]\n","\n","    for _ in range(next_words):\n","        encoded = tokenizer.texts_to_sequences([' '.join(result)])[0]\n","        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre')\n","        preds = model.predict(encoded, verbose=0)[0]\n","        next_index = np.argmax(preds)\n","        next_word = tokenizer.index_word.get(next_index, '')\n","        if next_word == '':\n","            break\n","        result.append(next_word)\n","    return ' '.join(result)\n","\n","\n","print(generate_story(model, tokenizer, \"Spot\"))\n"],"metadata":{"id":"4d1gmKdW70xy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"y16GvmtO5jUB"},"execution_count":null,"outputs":[]}]}