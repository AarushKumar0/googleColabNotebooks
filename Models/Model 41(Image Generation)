{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNa0ukGmELP7gvVp2poVKPx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"p2rFqqV8G_lX"},"outputs":[],"source":["# -------------------------------\n","# 1. Install required libraries\n","# -------------------------------\n","!pip install torch torchvision tqdm pillow\n","\n","# -------------------------------\n","# 2. Imports\n","# -------------------------------\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from PIL import Image\n","from tqdm import tqdm\n","import pandas as pd\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","# -------------------------------\n","# 3. Mount Google Drive and load dataset\n","# -------------------------------\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set dataset path\n","DATA_DIR = \"/content/drive/MyDrive/StableDiffusion100k/images\"  # adjust path\n","PROMPT_CSV = \"/content/drive/MyDrive/StableDiffusion100k/prompts.csv\"\n","\n","# Load prompts CSV\n","df = pd.read_csv(PROMPT_CSV)\n","print(df.head())\n","\n","# -------------------------------\n","# 4. Custom Dataset\n","# -------------------------------\n","class ImagePromptDataset(Dataset):\n","    def __init__(self, df, image_dir, transform=None):\n","        self.df = df\n","        self.image_dir = image_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        img_path = os.path.join(self.image_dir, self.df.iloc[idx]['image_path'])\n","        image = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","        # For simple GAN, we ignore prompts, just generate images\n","        return image\n","\n","# Image transformations\n","transform = transforms.Compose([\n","    transforms.Resize((64, 64)),  # DCGAN usually uses 64x64\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5]*3, [0.5]*3)  # normalize to [-1,1]\n","])\n","\n","dataset = ImagePromptDataset(df, DATA_DIR, transform)\n","dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2)\n","\n","# -------------------------------\n","# 5. Define Custom DCGAN Model\n","# -------------------------------\n","# Generator\n","class Generator(nn.Module):\n","    def __init__(self, nz=100, ngf=64, nc=3):\n","        super().__init__()\n","        self.main = nn.Sequential(\n","            # Input: latent vector Z\n","            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf*8),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf*4),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf*2),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","\n","            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n","            nn.Tanh()  # output in [-1,1]\n","        )\n","\n","    def forward(self, x):\n","        return self.main(x)\n","\n","# Discriminator\n","class Discriminator(nn.Module):\n","    def __init__(self, nc=3, ndf=64):\n","        super().__init__()\n","        self.main = nn.Sequential(\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf*2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf*4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf*8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","\n","            nn.Conv2d(ndf*8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.main(x).view(-1, 1).squeeze(1)\n","\n","# Initialize models\n","nz = 100  # latent vector size\n","G = Generator(nz=nz).to(device)\n","D = Discriminator().to(device)\n","\n","# -------------------------------\n","# 6. Loss and Optimizers\n","# -------------------------------\n","criterion = nn.BCELoss()\n","optimizerD = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","optimizerG = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","# -------------------------------\n","# 7. Training Loop\n","# -------------------------------\n","epochs = 20\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","for epoch in range(epochs):\n","    for i, real_images in enumerate(tqdm(dataloader)):\n","        real_images = real_images.to(device)\n","        b_size = real_images.size(0)\n","        real_labels = torch.ones(b_size, device=device)\n","        fake_labels = torch.zeros(b_size, device=device)\n","\n","        # -------------------------------\n","        # Train Discriminator\n","        # -------------------------------\n","        D.zero_grad()\n","        output_real = D(real_images)\n","        loss_real = criterion(output_real, real_labels)\n","\n","        noise = torch.randn(b_size, nz, 1, 1, device=device)\n","        fake_images = G(noise)\n","        output_fake = D(fake_images.detach())\n","        loss_fake = criterion(output_fake, fake_labels)\n","\n","        lossD = loss_real + loss_fake\n","        lossD.backward()\n","        optimizerD.step()\n","\n","        # -------------------------------\n","        # Train Generator\n","        # -------------------------------\n","        G.zero_grad()\n","        output_fake2 = D(fake_images)\n","        lossG = criterion(output_fake2, real_labels)  # trick discriminator\n","        lossG.backward()\n","        optimizerG.step()\n","\n","    print(f\"Epoch [{epoch+1}/{epochs}] Loss D: {lossD.item():.4f}, Loss G: {lossG.item():.4f}\")\n","\n","# -------------------------------\n","# 8. Save Models\n","# -------------------------------\n","torch.save(G.state_dict(), \"/content/drive/MyDrive/DCGAN_G.pth\")\n","torch.save(D.state_dict(), \"/content/drive/MyDrive/DCGAN_D.pth\")\n","\n","# -------------------------------\n","# 9. Generate Images\n","# -------------------------------\n","import matplotlib.pyplot as plt\n","\n","G.eval()\n","with torch.no_grad():\n","    fake_images = G(fixed_noise).cpu()\n","    # Denormalize\n","    fake_images = (fake_images + 1) / 2\n","\n","fig, axes = plt.subplots(8, 8, figsize=(12,12))\n","for i, ax in enumerate(axes.flatten()):\n","    ax.imshow(fake_images[i].permute(1,2,0))\n","    ax.axis('off')\n","plt.show()\n"]}]}